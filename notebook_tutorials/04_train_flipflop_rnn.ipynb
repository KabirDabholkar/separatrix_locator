{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Tutorial 04: Training an RNN on the Flip-Flop Task\n",
        "\n",
        "In this tutorial we will walk through a two-part workflow using the utilities provided in `separatrix_locator.dynamics`:\n",
        "\n",
        "1. Train a recurrent neural network on the classic flip-flop task and inspect its behaviour.\n",
        "2. Treat the trained RNN as a dynamical system, extract its autonomous dynamics, and run the separatrix locator on that learned vector field.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install the package when running in Colab\n",
        "# !pip install git+https://github.com/KabirDabholkar/separatrix_locator.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 1 · Train the Flip-Flop RNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "from separatrix_locator.distributions import MultivariateGaussian, multiscaler\n",
        "\n",
        "from separatrix_locator.dynamics import (\n",
        "    FlipFlopDataset,\n",
        "    FlipFlopSweepDataset,\n",
        "    TrainingConfig,\n",
        "    train_flipflop_rnn,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration for the flip-flop dataset and training loop\n",
        "n_bits = 1\n",
        "n_time = 50\n",
        "n_trials = 32\n",
        "repeats = 5\n",
        "random_seed = 2\n",
        "\n",
        "save_dir = Path(\"../rnn_params/tutorial_outputs/flipflop_rnn\")\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "training_config = TrainingConfig(\n",
        "    epochs=1000,\n",
        "    log_interval=50,\n",
        "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
        "    save_dir=save_dir,\n",
        "    save_checkpoint=True,\n",
        "    save_loss_plot=True,\n",
        ")\n",
        "\n",
        "# Instantiate dataset callables\n",
        "train_dataset = FlipFlopDataset(\n",
        "    n_trials=n_trials,\n",
        "    repeats=repeats,\n",
        "    n_time=n_time,\n",
        "    n_bits=n_bits,\n",
        "    p=0.2,\n",
        "    random_seed=random_seed,\n",
        ")\n",
        "\n",
        "analysis_dataset = FlipFlopSweepDataset(\n",
        "    n_trials=16,\n",
        "    repeats=repeats,\n",
        "    n_time=n_time,\n",
        "    n_bits=n_bits,\n",
        "    p=0.2,\n",
        "    random_seed=random_seed,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "result = train_flipflop_rnn(\n",
        "    dataset=train_dataset,\n",
        "    input_size=n_bits,\n",
        "    output_size=n_bits,\n",
        "    hidden_size=64,\n",
        "    training_config=training_config,\n",
        ")\n",
        "\n",
        "print(f\"Training finished with {len(result.loss_history)} iterations.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.plot(result.loss_history)\n",
        "plt.xlabel(\"Iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training Loss Curve\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs_train, outputs_train = result.evaluate(train_dataset)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "\n",
        "# Plot all input bits with solid lines\n",
        "for i in range(1):\n",
        "    ax.plot(inputs_train[:, i, 0], label=f\"Train input bit {i+1}\", linestyle='-', alpha=0.7)\n",
        "\n",
        "# Plot all output bits with dashed lines\n",
        "for i in range(1):\n",
        "    ax.plot(outputs_train[:, i, 0], label=f\"Train output bit {i+1}\", linestyle='-', alpha=0.9)\n",
        "\n",
        "ax.set_xlabel(\"Time step\")\n",
        "ax.set_ylabel(\"Value\")\n",
        "ax.set_title(\"Flip-Flop Task: Inputs and Network Outputs\")\n",
        "# ax.legend(loc=\"best\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "\n",
        "inputs, outputs = result.evaluate(analysis_dataset)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 4))\n",
        "\n",
        "n_bits = inputs.shape[1]\n",
        "cmap = matplotlib.colormaps[\"Blues\"]\n",
        "\n",
        "for i in range(n_bits):\n",
        "    color = cmap((i + 1) / n_bits)\n",
        "    ax.plot(inputs[:, i, 0], label=f\"Input bit {i+1}\", linestyle='-', alpha=0.7, color=color)\n",
        "    ax.plot(outputs[:, i, 0], label=f\"Output bit {i+1}\", linestyle='--', alpha=0.9, color=color)\n",
        "\n",
        "ax.set_xlabel(\"Time step\")\n",
        "ax.set_ylabel(\"Value\")\n",
        "# ax.legend()\n",
        "ax.set_title(\"Flip-Flop Task: Inputs and Network Outputs\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib\n",
        "\n",
        "hidden, hidden_pca, explained = result.compute_hidden_pca(analysis_dataset, n_components=2)\n",
        "\n",
        "print(f\"Explained variance ratio: PC1={explained[0]:.3f}, PC2={explained[1]:.3f}\")\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "n_trials = hidden_pca.shape[1]\n",
        "cmap = matplotlib.colormaps[\"Blues\"]\n",
        "for trial_idx in range(n_trials):\n",
        "    color = cmap((trial_idx + 1) / max(8, n_trials))\n",
        "    # Plot trajectory\n",
        "    plt.plot(\n",
        "        hidden_pca[:, trial_idx, 0],\n",
        "        hidden_pca[:, trial_idx, 1],\n",
        "        alpha=0.7,\n",
        "        label=f\"Trial {trial_idx + 1}\",\n",
        "        color=color,\n",
        "    )\n",
        "    # Mark the final point with a scatter plot\n",
        "    plt.scatter(\n",
        "        hidden_pca[-1, trial_idx, 0],\n",
        "        hidden_pca[-1, trial_idx, 1],\n",
        "        color=color,\n",
        "        edgecolor='black',\n",
        "        s=60,\n",
        "        zorder=5\n",
        "    )\n",
        "\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "plt.title(\"Hidden State Trajectories (PCA)\")\n",
        "# plt.legend(loc=\"best\")\n",
        "plt.grid(alpha=0.3)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Part 2 · Extract RNN Dynamics and Locate the Separatrix\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this section we:\n",
        "\n",
        "- extract the autonomous hidden-state dynamics from the trained GRU\n",
        "- build a distribution over visited hidden states\n",
        "- train a small Koopman-eigenfunction ensemble with `SeparatrixLocator`\n",
        "- run gradient descent on the learned eigenfunctions to approximate separatrix points\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from separatrix_locator.dynamics.rnn import (\n",
        "    discrete_to_continuous,\n",
        "    get_autonomous_dynamics_from_model,\n",
        "    hidden_distribution_with_spectral_norm,\n",
        ")\n",
        "from separatrix_locator.core import SeparatrixLocator\n",
        "from separatrix_locator.core.models import ResNet\n",
        "from separatrix_locator.utils.odeint_utils import run_odeint_to_final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Gather hidden-state trajectories on the analysis sweep and fit a Gaussian distribution\n",
        "result.model.eval()\n",
        "with torch.no_grad():\n",
        "    inputs_eval, _ = analysis_dataset()\n",
        "    inputs_eval_tensor = torch.from_numpy(inputs_eval).to(result.device, dtype=torch.float32)\n",
        "    _, hidden_eval = result.model(inputs_eval_tensor, return_hidden=True)\n",
        "\n",
        "hidden_eval_cpu = hidden_eval.detach().cpu()\n",
        "hidden_eval_flat = hidden_eval_cpu.reshape(-1, hidden_eval_cpu.shape[-1])\n",
        "hidden_distribution = hidden_distribution_with_spectral_norm(hidden_eval_flat)\n",
        "\n",
        "hidden_dim = hidden_eval_cpu.shape[-1]\n",
        "print(f\"Hidden-state dimension: {hidden_dim}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build a differentiable vector field from the trained recurrent weights\n",
        "result.model.to(result.device)\n",
        "autonomous_dynamics = get_autonomous_dynamics_from_model(result.model, device=str(result.device))\n",
        "continuous_vector_field = discrete_to_continuous(autonomous_dynamics, delta_t=1.0)\n",
        "\n",
        "def rnn_vector_field(x: torch.Tensor) -> torch.Tensor:\n",
        "    with torch.no_grad():\n",
        "        return continuous_vector_field(x)\n",
        "\n",
        "# Sanity check on a batch of hidden states\n",
        "sample_states = hidden_distribution.sample((8,)).to(result.device)\n",
        "vector_field_sample = rnn_vector_field(sample_states)\n",
        "print(f\"Vector field output shape: {vector_field_sample.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sample initial conditions from the hidden state distribution\n",
        "num_samples = 256\n",
        "init_states = hidden_distribution.sample((num_samples,)).to(result.device)\n",
        "\n",
        "# Integrate each initial condition trajectory with the learned RNN vector field\n",
        "T = 500.0\n",
        "steps = 100\n",
        "with torch.no_grad():\n",
        "    # Run trajectories: shape (steps, num_samples, hidden_dim)\n",
        "    traj = run_odeint_to_final(\n",
        "        func=continuous_vector_field,\n",
        "        y0=init_states,\n",
        "        T=T,\n",
        "        steps=steps,\n",
        "        return_last_only=False,\n",
        "        no_grad=True,\n",
        "    )  # shape (steps, num_samples, hidden_dim)\n",
        "\n",
        "# Reshape for PCA: concatenate all timepoints and samples to (steps*num_samples, hidden_dim)\n",
        "traj_flat = traj.cpu().numpy().reshape(-1, hidden_dim)\n",
        "\n",
        "# Fit PCA on the entire trajectory\n",
        "pca = PCA(n_components=2)\n",
        "traj_pca = pca.fit_transform(traj_flat)\n",
        "\n",
        "# For coloring, we use time steps (repeat for each sample)\n",
        "time_steps = np.arange(steps)\n",
        "plot_time = np.repeat(time_steps, num_samples)\n",
        "\n",
        "# Plot trajectories in PCA space (faint lines for each trajectory)\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "# Store all endpoints for scatter\n",
        "endpoints_pca = []\n",
        "for i in range(num_samples):\n",
        "    seg = traj[:, i, :].cpu().numpy()\n",
        "    seg_pca = pca.transform(seg)\n",
        "    ax.plot(seg_pca[:, 0], seg_pca[:, 1], alpha=0.4)\n",
        "    endpoints_pca.append(seg_pca[-1])\n",
        "\n",
        "endpoints_pca = np.stack(endpoints_pca)\n",
        "ax.scatter(endpoints_pca[:, 0], endpoints_pca[:, 1], color='red', label='End points', s=24, marker='o', zorder=3)\n",
        "ax.set_title(\"RNN hidden state trajectories in PCA space\")\n",
        "ax.set_xlabel(\"PC 1\")\n",
        "ax.set_ylabel(\"PC 2\")\n",
        "ax.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Extracting attractors and a separatrix point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Get endpoints for each sample trajectory (shape: num_samples x hidden_dim)\n",
        "traj_endpoints = traj[-1].cpu().numpy()\n",
        "\n",
        "# Run k-means (k=2) on the endpoints to find two attractors in hidden state space\n",
        "kmeans = KMeans(n_clusters=2, random_state=42)\n",
        "kmeans.fit(traj_endpoints)\n",
        "attractors = kmeans.cluster_centers_\n",
        "# print(\"Identified attractors (in hidden_dim):\\n\", attractors)\n",
        "print(attractors.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Finding a point on the separatrix by interpolating between attractors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from separatrix_locator.core.separatrix_point import find_separatrix_point_along_line\n",
        "point_on_separatrix = find_separatrix_point_along_line(\n",
        "    dynamics_function=rnn_vector_field,\n",
        "    external_input=None,\n",
        "    attractors=torch.from_numpy(attractors).type(torch.float32),\n",
        "    num_points=20,\n",
        "    num_iterations=2,\n",
        "    final_time=500.0,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training distributions: centered at separatrix point, with multiple scales"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "distribution = MultivariateGaussian(\n",
        "    dim = hidden_dim,\n",
        "    mean=point_on_separatrix, \n",
        "    covariance_matrix=torch.eye(hidden_dim) * 2.0\n",
        ")\n",
        "multiscaled_distribution = multiscaler(distribution, [0.1, 1.0, 3.0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Training Koopman Eigenfunction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure Separatrix Locator\n",
        "num_models = 1\n",
        "locator_models = [ResNet(input_dim=hidden_dim, hidden_size=500, output_dim=1, num_layers=8, input_scale_factor=1.0) for _ in range(num_models)]\n",
        "for model in locator_models:\n",
        "    model.to(result.device)\n",
        "\n",
        "locator = SeparatrixLocator(\n",
        "    num_models=num_models,\n",
        "    dynamics_dim=hidden_dim,\n",
        "    models=locator_models,\n",
        "    lr=1e-3,\n",
        "    epochs=500,\n",
        "    use_multiprocessing=False,\n",
        "    verbose=True,\n",
        "    device=str(result.device),\n",
        ")\n",
        "locator.to(str(result.device))\n",
        "\n",
        "# Train Koopman eigenfunction models on the learned dynamics\n",
        "results = locator.fit(\n",
        "    func=rnn_vector_field,\n",
        "    distribution=multiscaled_distribution,\n",
        "    dist_requires_dim=False,\n",
        "    batch_size=256,\n",
        "    eigenvalue=1.0,\n",
        "    print_every_num_epochs=50,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Validating Separatrix Locator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from separatrix_locator.plotting.hermite import find_separatrix_along_curve_using_ODE\n",
        "from separatrix_locator.utils.interpolation import generate_curves_between_points\n",
        "\n",
        "num_points = 100\n",
        "\n",
        "alphas = np.linspace(0, 1, num_points)\n",
        "\n",
        "curve_points = generate_curves_between_points(\n",
        "    x=attractors[0],\n",
        "    y=attractors[1],\n",
        "    num_curves=100,\n",
        "    num_points=num_points,\n",
        "    rand_scale=3.0,\n",
        ")\n",
        "\n",
        "change_points_alpha, labels_bt = find_separatrix_along_curve_using_ODE(\n",
        "    dynamics_function=rnn_vector_field,\n",
        "    attractors=torch.from_numpy(attractors),\n",
        "    alphas=alphas,\n",
        "    curve_points=curve_points,\n",
        "    integration_time=500.0,\n",
        "    attractor_epsilon=0.02,\n",
        "    kmeans_random_state=42,\n",
        "    clustering_method=\"attractor_eps\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "num_curves, num_points, dim = curve_points.shape\n",
        "\n",
        "# Flatten curves for PCA (shape: num_curves * num_points, dim)\n",
        "curve_points_flat = curve_points.reshape(-1, curve_points.shape[-1])\n",
        "\n",
        "# Perform PCA to 2D\n",
        "pca = PCA(n_components=2)\n",
        "curve_points_pca = pca.fit_transform(curve_points_flat)\n",
        "curve_points_pca_bt = curve_points_pca.reshape(num_curves, num_points, 2)\n",
        "\n",
        "# Prepare color labels (shape: num_curves, num_points)\n",
        "labels_bt = labels_bt\n",
        "\n",
        "plt.figure(figsize=(7, 7))\n",
        "for i in range(num_curves):\n",
        "    # Pick one color for the label of each curve, or color by label at each point\n",
        "    # Here we color *segments* by the basin label at each segment\n",
        "    for j in range(num_points-1):\n",
        "        color = plt.cm.coolwarm(labels_bt[i,j] / (labels_bt.max() if labels_bt.max()>0 else 1))\n",
        "        plt.plot(\n",
        "            curve_points_pca_bt[i, j:j+2, 0],\n",
        "            curve_points_pca_bt[i, j:j+2, 1],\n",
        "            color=color,\n",
        "            alpha=0.8,\n",
        "            linewidth=1,\n",
        "        )\n",
        "    # Mark the change point with an 'x'\n",
        "    # Find the change point index along this curve\n",
        "    change_alpha = change_points_alpha[i]\n",
        "    # Each curve goes from alpha=0 to alpha=1 uniformly spaced, so map change_alpha to nearest point\n",
        "    change_idx = np.argmin(np.abs(np.linspace(0, 1, num_points) - change_alpha))\n",
        "    plt.plot(\n",
        "        curve_points_pca_bt[i, change_idx, 0],\n",
        "        curve_points_pca_bt[i, change_idx, 1],\n",
        "        marker='x',\n",
        "        markersize=8,\n",
        "        markeredgewidth=2,\n",
        "        color='black',\n",
        "        linestyle='None',\n",
        "        label=\"Change point\" if i == 0 else None,  # Label only once for legend\n",
        "    )\n",
        "\n",
        "plt.title(\"Hermite curves (PCA) colored by basin labels\\nChange points marked with x's\")\n",
        "plt.xlabel(\"PC1\")\n",
        "plt.ylabel(\"PC2\")\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "KEFvals = locator.predict(torch.from_numpy(curve_points).type(torch.float32))\n",
        "l=plt.plot(KEFvals[:,:,0].T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_idx = torch.argmin(torch.abs(KEFvals)[...,0], dim=1)\n",
        "zero_point_alphas = alphas[min_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.scatter(change_points_alpha,zero_point_alphas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### do the validation with a single method call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "r2score = locator.validate_with_curves(\n",
        "    dynamics_function=rnn_vector_field,\n",
        "    attractors=torch.from_numpy(attractors).type(torch.float32),\n",
        "    num_curves=100,\n",
        "    num_points=100,\n",
        "    rand_scale=3.0,\n",
        "    alpha_lims=(0.0, 1.0),\n",
        "    integration_time=500.0,\n",
        "    attractor_epsilon = 0.02,\n",
        "    kmeans_random_state = 42,\n",
        "    clustering_method = \"attractor_eps\",\n",
        "    kef_component = 0,\n",
        "    plot_pca = True,\n",
        "    plot_kef = True,\n",
        "    plot_scatter = True,\n",
        ")\n",
        "print(\"Curves R2 score:\",r2score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare the trained models for separatrix search and run gradient descent\n",
        "_ = locator.prepare_models_for_gradient_descent(\n",
        "    distribution=hidden_distribution,\n",
        "    dist_needs_dim=False,\n",
        ")\n",
        "\n",
        "gd_trajectories, separatrix_points = locator.find_separatrix(\n",
        "    distribution=hidden_distribution,\n",
        "    dist_needs_dim=False,\n",
        "    batch_size=96,\n",
        "    num_steps=200,\n",
        "    threshold=5e-2,\n",
        ")\n",
        "\n",
        "if separatrix_points:\n",
        "    print(f\"Collected {len(separatrix_points)} sets of candidate separatrix points.\")\n",
        "    for idx, pts in enumerate(separatrix_points[:2]):\n",
        "        print(f\"Model {idx} candidate count: {pts.shape[0]}\")\n",
        "else:\n",
        "    print(\"No separatrix candidates found — consider adjusting threshold or training settings.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualise separatrix candidates in the leading PCA plane of the hidden states\n",
        "if separatrix_points and separatrix_points[0].numel() > 0:\n",
        "    from sklearn.decomposition import PCA\n",
        "\n",
        "    pca = PCA(n_components=2)\n",
        "    hidden_pca_flat = pca.fit_transform(hidden_eval_flat.numpy())\n",
        "\n",
        "    sep_proj = [pca.transform(pts.cpu().numpy()) for pts in separatrix_points if pts.numel() > 0]\n",
        "\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    plt.scatter(\n",
        "        hidden_pca_flat[:, 0],\n",
        "        hidden_pca_flat[:, 1],\n",
        "        alpha=0.1,\n",
        "        label=\"Hidden states\",\n",
        "    )\n",
        "    for idx, proj in enumerate(sep_proj):\n",
        "        plt.scatter(\n",
        "            proj[:, 0],\n",
        "            proj[:, 1],\n",
        "            s=40,\n",
        "            label=f\"Separatrix candidates (model {idx})\",\n",
        "        )\n",
        "    plt.xlabel(\"PC1\")\n",
        "    plt.ylabel(\"PC2\")\n",
        "    plt.legend()\n",
        "    plt.title(\"Separatrix locator candidates in hidden-state PCA space\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No separatrix candidates to visualise.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next steps\n",
        "\n",
        "- Experiment with different hidden sizes or cell types by passing `cell_type=\"LSTM\"` to `train_flipflop_rnn`.\n",
        "- Adjust the dataset parameters to make the task harder (e.g., more bits or longer sequences).\n",
        "- Swap in alternative hidden-state distributions (e.g., PCA-reduced Gaussians) before running `SeparatrixLocator`.\n",
        "- Tune the Koopman ensemble size, training epochs, or gradient-descent thresholds to sharpen the separatrix estimate.\n",
        "- Use the trained checkpoint saved in `tutorial_outputs/flipflop_rnn` to initialise other analyses in the separatrix locator pipeline.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
